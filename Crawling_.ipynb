{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import numpy as np\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "Stock_List_Url = 'https://www.advfn.com/nasdaq/nasdaq.asp?companies='\n",
    "Yahoo_Url_Stat1 = 'https://finance.yahoo.com/quote/'\n",
    "Yahoo_Url_Stat2 = '/key-statistics?p='\n",
    "Finviz_Url = 'https://finviz.com/quote.ashx?t='\n",
    "Wsj_Url1 = 'https://www.wsj.com/market-data/quotes/'\n",
    "Wsj_Url2 = '/financials/quarter/income-statement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52743df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Symbols = [] #www.advfn.com\n",
    "Avg_50 = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Avg_200 = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Week_52_High = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Week_52_Low = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Perf_Month = [] #Change of the stock in the last Month    #https://finviz.com/quote.ashx?t=\n",
    "Perf_Quarter = [] #Change of the stock in the last Quarter    #https://finviz.com/quote.ashx?t=\n",
    "Perf_Half_Year = [] #https://finviz.com/quote.ashx?t=\n",
    "Perf_Year = [] #https://finviz.com/quote.ashx?t=\n",
    "Perf_Week = [] #https://finviz.com/quote.ashx?t=\n",
    "Avg_3_Month = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Vol_Avg_10_Day = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Vol_Avg_3_Months = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Predict_Of_Price = [] #Prediction of the project!!\n",
    "Current_Stock_Price = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Held_By_Institusion = [] #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Analyst_Mean_Target_Price = []  #https://finance.yahoo.com/quote//key-statistics?p=\n",
    "Sectors = [] #https://finance.yahoo.com/quote//profile?p=\n",
    "\n",
    "#Done the crawling for these cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \n",
    "           'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "for letter in letters:\n",
    "    New_Stock_List_Url = Stock_List_Url + letter\n",
    "    response  = requests.get(New_Stock_List_Url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    odd_rows = soup.find_all('tr', attrs = {\"class\" : 'ts1'})\n",
    "    even_rows = soup.find_all('tr' , attrs = {\"class\" : 'ts0'}) \n",
    "\n",
    "    for item in odd_rows:\n",
    "        stock = item.find_all('td')\n",
    "        Symbols.append(stock[1].get_text())\n",
    "\n",
    "    for item in even_rows:\n",
    "        stock = item.find_all('td')\n",
    "        Symbols.append(stock[1].get_text())\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d8e61",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af57d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "proxies = {\"https\": \"http://93.160.60.22:443\"}\n",
    "for symbol in Symbols:\n",
    "    try:\n",
    "        New_Yahoo_Url = Yahoo_Url_Stat1 + symbol + Yahoo_Url_Stat2 + symbol\n",
    "        response = requests.get(New_Yahoo_Url, headers = user_agent) \n",
    "    except:\n",
    "        response = requests.get(New_Yahoo_Url, headers = user_agent, proxies=proxies) \n",
    "        \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    print(i)\n",
    "    i+=1\n",
    "    \n",
    "    try:\n",
    "        tables = soup.find('div', class_= 'Pstart(20px) smartphone_Pstart(0px)')\n",
    "        table = tables.find_all('table', class_= 'W(100%) Bdcl(c)')\n",
    "    except:\n",
    "        Symbols.remove(symbol)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "\n",
    "        Data_Get1 = table[0].find_all('td', attrs = {'class' : 'Fw(500) Ta(end) Pstart(10px) Miw(60px)'})\n",
    "\n",
    "        \n",
    "        try: \n",
    "            Week_52_High.append(Data_Get1[3].get_text())\n",
    "            print(Data_Get1[3].get_text())\n",
    "        except:\n",
    "            Week_52_High.append(np.nan)\n",
    "\n",
    "\n",
    "        try:\n",
    "            Week_52_Low.append(Data_Get1[4].get_text())\n",
    "            print(Data_Get1[4].get_text())\n",
    "        except:\n",
    "            Week_52_Low.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            Avg_50.append(Data_Get1[5].get_text())\n",
    "            print(Data_Get1[5].get_text())\n",
    "\n",
    "        except:\n",
    "            Avg_50.append(np.nan)\n",
    "            \n",
    "        try:\n",
    "            Avg_200.append(Data_Get1[6].get_text())\n",
    "            print(Data_Get1[6].get_text())\n",
    "        except:\n",
    "            Avg_200.append(np.nan)\n",
    "\n",
    "    except:\n",
    "        Avg_200.append(np.nan)\n",
    "        Week_52_High.append(np.nan)\n",
    "        Week_52_Low.append(np.nan)\n",
    "        Avg_50.append(np.nan)\n",
    "\n",
    "    ## table 2\n",
    "    try:\n",
    "\n",
    "        Data_Get2 = table[1].find_all('td', attrs = {'class' : 'Fw(500) Ta(end) Pstart(10px) Miw(60px)'})\n",
    "\n",
    "        try:\n",
    "            Vol_Avg_3_Months.append(Data_Get2[0].get_text())\n",
    "            print(Data_Get2[0].get_text())\n",
    "        except:\n",
    "            Vol_Avg_3_Months.append(np.nan)\n",
    "    \n",
    "        try:\n",
    "            Vol_Avg_10_Day.append(Data_Get2[1].get_text())\n",
    "            print(Data_Get2[1].get_text())\n",
    "        except:\n",
    "            Vol_Avg_10_Day.append(np.nan)\n",
    "    \n",
    "        try:\n",
    "            Held_By_Institusion.append(Data_Get2[6].get_text())\n",
    "            print(Data_Get2[6].get_text())\n",
    "        except:\n",
    "            Held_By_Institusion.append(np.nan)\n",
    "    except:\n",
    "        Vol_Avg_3_Months.append(np.nan)\n",
    "        Vol_Avg_10_Day.append(np.nan)\n",
    "        Held_By_Institusion.append(np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca467752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yahoo = pd.DataFrame({'Symbols':Symbols, 'Avg_50':Avg_50, 'Avg_200':Avg_200, 'Week_52_High':Week_52_High, 'Week_52_Low':Week_52_Low, 'Vol_Avg_10_Day':Vol_Avg_10_Day, 'Vol_Avg_3_Months':Vol_Avg_3_Months, 'Held_By_Institusion':Held_By_Institusion})\n",
    "df_yahoo.to_csv('Yahoo_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41aedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in Symbols:\n",
    "    New_Finviz_Url = Finviz_Url + symbol\n",
    "    response = requests.get(New_Finviz_Url, headers = user_agent)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    trs = soup.find_all('tr', attrs = {'class': 'table-dark-row'})\n",
    "    \n",
    "    tds = trs[0].find_all('td')\n",
    "    try:\n",
    "        Perf_Week.append(tds[11].get_text())\n",
    "    except:\n",
    "        Perf_Week.append(np.nan)\n",
    "    \n",
    "    tds = trs[1].find_all('td')\n",
    "    try:\n",
    "        Perf_Month.append(tds[11].get_text()) \n",
    "    except:\n",
    "        Perf_Month.append(np.nan)\n",
    "    \n",
    "    tds = trs[2].find_all('td')\n",
    "    try:\n",
    "        Perf_Quarter.append(tds[11].get_text()) \n",
    "    except:\n",
    "        Perf_Quarter.append(np.nan)\n",
    "    \n",
    "    tds = trs[3].find_all('td')\n",
    "    try:\n",
    "        Perf_Half_Year.append(tds[11].get_text()) \n",
    "    except:\n",
    "        Perf_Half_Year.append(np.nan)\n",
    "    \n",
    "    tds = trs[4].find_all('td')\n",
    "    try:\n",
    "        Perf_Year.append(tds[11].get_text()) \n",
    "    except:\n",
    "        Perf_Year.append(np.nan)\n",
    "    \n",
    "    tds = trs[4].find_all('td')\n",
    "    try:\n",
    "        Analyst_Mean_Target_Price.append(tds[9].get_text())\n",
    "    except:\n",
    "        Analyst_Mean_Target_Price.append(np.nan)\n",
    "    \n",
    "    tds = trs[10].find_all('td')\n",
    "    try:\n",
    "        Current_Stock_Price.append(tds[11].get_text())\n",
    "    except:\n",
    "         Current_Stock_Price.append(np.nan)\n",
    "    time.sleep(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9700147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finviz = pd.DataFrame({\"Perf_Week\": Perf_Week,\"Perf_Month\":Perf_Month, \"Perf_Quarter\":Perf_Quarter, \"Perf_Half_Year\": Perf_Half_Year, \"Perf_Year\":Perf_Year,\"Analyst_Mean_Target_Price\":Analyst_Mean_Target_Price,\"Current_Stock_Price\":Current_Stock_Price})\n",
    "df_finviz.to_csv('fin-viz_data_Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c0b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(PATH)\n",
    "Q_Net = [[], []] \n",
    "i=1\n",
    "url='https://finviz.com/quote.ashx?t='\n",
    "for symbol in Symbols:\n",
    "    driver.get(url + symbol)\n",
    "    print(\"menaya:\" ,i)\n",
    "    i+=1\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        driver.find_element(By.CSS_SELECTOR,'#statements > table.fullview-links > tbody > tr > td:nth-child(2) > a:nth-child(2)').click()\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            q1=driver.find_element(By.XPATH,'//*[@id=\"statements\"]/table[2]/tbody/tr[15]/td[3]').text\n",
    "            print(q1)\n",
    "            Q_Net[0].append(q1)\n",
    "        except:\n",
    "            print('helem')\n",
    "            Q_Net[0].append(np.nan)\n",
    "        try:\n",
    "            q2=driver.find_element(By.XPATH,'//*[@id=\"statements\"]/table[2]/tbody/tr[15]/td[4]').text\n",
    "            print(q2)\n",
    "            Q_Net[1].append(q2)\n",
    "        except:\n",
    "            print('helem')\n",
    "            Q_Net[1].append(np.nan)       \n",
    "    except:\n",
    "        print('HELEM')\n",
    "        Q_Net[0].append(np.nan)\n",
    "        Q_Net[1].append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Net_Income = pd.DataFrame({'Last_Q_Net':Q_Net[0], 'Prev_Q_Net':Q_Net[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131541ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Net_Income.to_csv('net_income_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Yahoo_data.csv')\n",
    "df2=pd.read_csv('fin-viz_data_Complete.csv')\n",
    "df3=pd.read_csv('net_income_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e00bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1.merge(df2)\n",
    "Complete_df=df.merge(df3)\n",
    "Complete_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56faaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d0508",
   "metadata": {},
   "source": [
    "# crawling the sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url1='https://finance.yahoo.com/quote/'\n",
    "url2='/profile?p='\n",
    "i=1\n",
    "for symbol in Symbols:\n",
    "    driver.get(url1 + symbol+ url2 + symbol)\n",
    "    time.sleep(2)\n",
    "    print(\"menaya:\" ,i)\n",
    "    i+=1\n",
    "    try:\n",
    "        sec=driver.find_element(By.XPATH,'//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[2]').text\n",
    "        print(sec)\n",
    "        Sectors.append(sec)\n",
    "    except:\n",
    "        Sectors.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complete_df[\"Sectors\"] = Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae26cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complete_df.to_csv('Complete_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2b9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
